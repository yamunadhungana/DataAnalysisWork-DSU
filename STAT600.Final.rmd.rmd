---
title: "Final_Project"
author: "Yamuna Dhungana"
date: "8/7/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Outline of the Project
This project is the extinsion of the Mid- term project,here we are given two additional data
of 2013 and2018 to evaluate. We will be evaluating the data according to the yeild for each 
year.


## Algorithm and uses
1. I downloaded the libraries that I will be using in the project.
2. I read the data and gave the name as df_(years) for each year data
3. I created a function where I wrote a code to find out the required grid cell from the
midterm with come updates.
4. In the same chunk, I have enclosed a function to calculate the aggregate mean yield for
the single grid cell, that will give us aggregated 120 yields for each grid cell
5. I have also enclosed a function to check if the time of the harvest date is within 7 days.
6. Then, I used this function for each year's data.
7. I plotted a graph to visualize the given data according to the grid cell and plotted 500 
points to visualize.
8. Before merging the data, there are two conditions to be fulfilled
   (a) The harvest should be less than 7 days
   (b) The data should be normalized with either of the given three options
9. I checked the given condition with the function mentioned in the step. 5 
10. If the condition is satisfied, I normalized the data using the first option that is Rank.
11. I finally merged the all data of 5 years according to the grid cell and named it as final data.
12. Now I calculated the normalized mean and standard deviation for uniformity.
13. I applied the quartile method to find out the highest 25% and lowest 25% of normalized data.
I plotted a box-plot to visualize.
14. Finally, I classified the result of quartiles as low high and moderate for mean and stable yield,
Average yield and unstable yield for sd
15. Lastly, I plotted a graph for the classification by the mean and standard deviation.

```{r}
# I will be using following external library

library(ggplot2)
library(dplyr)
```

First of all, reading the data of 2013, 2015, 2016, 2017 and 2018  which is given in d2l as 
`df_2018,df_2017,df_2016,df_2015,df_2013` 

```{r}

# Reading the Harvst data
df_2018 <-
  read.table("https://raw.githubusercontent.com/yamunadhungana/finaldata/master/home.2018.csv",
             header = TRUE, sep = ",")
df_2017 <-
  read.table("https://raw.githubusercontent.com/yamunadhungana/finaldata/master/home.2017.csv",
             header = TRUE, sep = ",")
df_2016 <-
  read.table("https://raw.githubusercontent.com/yamunadhungana/finaldata/master/home.2016.csv",
             header = TRUE, sep = ",")
df_2015 <- 
  read.table("https://raw.githubusercontent.com/yamunadhungana/finaldata/master/home.2015.csv",
             header = TRUE, sep = ",")
df_2013 <- 
  read.table("https://raw.githubusercontent.com/yamunadhungana/finaldata/master/home.2013.csv",
             header = TRUE, sep = ",")
```


Below chuck includes the functions that is used in the project further:

1. codes for dividing the grid cell for 6x20 cells
2. code to calculate yeild estimates for each grid
3. codes to check the condition of the harvest time 

```{r}
# First of all, creating a function to divide the field with the help of
# the grid into 6 column and 20 rows field (6X20)

createPartitionsOf_6X20 <-
  function(df = df) {
    divLati <- 400 / 20
    divLong <- 600 / 6
    
    partitionsLat <- seq(0, 400, divLati)
    partitionsLon <- seq(0, 600, divLong)
    
    pos.matrix <-
      matrix(c(1:120),
             byrow = TRUE,
             nrow = 20)
    # pos.matrix <- apply(pos.matrix, 1, rev)
    # pos.matrix
    
    partitionMatrix <-
      cbind(findInterval(df[, "Latitude"], partitionsLat),
            findInterval(df[, "Longitude"], partitionsLon))

     choosePosition <- function(x) {
       pos.matrix[x[1], x[2]]
     }
    df$grids_gp <- apply(partitionMatrix, 1, choosePosition)
    
   
    return(df)
    
  }


# For calculating  Yield estimates for each cell
Each.cell.estimates <- function(df = df, testFunc = testFunc) {
  aggregate(df$Yield, by = list(df$grids_gp), FUN = testFunc)
}



# FUnction to check the condition of harvest time i.e 7 days
checknumberof_days <- function(mydata) {
  
  mydata$Date <- gsub(" .*", "", mydata$TimeStamp)
  mydata$Time <- gsub(".* ","", mydata$TimeStamp)
  
  # Range in days
  mydata$date_time <-
    as.POSIXct(paste(mydata$Date, mydata$Time), tz = "UTC")
  # mydata$date_time <- paste(mydata$Date, mydata$Time)
  
  # num_days <- round(difftime(max(as.POSIXct(mydata$date_time)),
  # min(as.POSIXct(mydata$date_time))), 3)
  num_days <-
    round(difftime(max(as.POSIXct(
      mydata$date_time
    )), min(as.POSIXct(
      mydata$date_time
    )), units = "days"), 3)
  
 # range_from_start_to_end_date_in_days <-
    if (num_days <= 7) {
      paste0(num_days, " days, so the data can be used for further calculation")
    } else if(num_days >= 7){
       paste0(num_days, " The data cannot be used because its harvest time is greater than 7")
    } 
  
}
#range_from_start_to_end_date_in_days


```
# Calculating for the year 2013 

First of all, in order to visualize how my field along with the grid and the position of 
the Latitude and longitude may look like, I have a function below:

```{r}

# Returning the values on the function creepartitionof_6x20
 newdf13 <-createPartitionsOf_6X20(df=df_2013)

# Plotting the limits of X and the y axis that is the size of the field
#set.seed(54321)
plot(NA,
  xlim = c(0, 600),
  ylim = c(0, 400),
  xlab = "Latitude",
  ylab = "Longitude",
  main = paste0(
    "Plot of data points at the desired grid(6x20) for the data 2013",
    sep = " "
  )
)


# plotting the required grid
grid(
  nx = 6,
  ny = 20,
  col = "blue",
  lty = "dotted",
  lwd = par("lwd"),
  equilogs = TRUE
)

colnames(newdf13)[colnames(newdf13) == "grid"] <-
  "grids_gp"

# I want to plot only 500 data's position in a graph to make it easier 
# to visualize
# inserting the 500 data's position
mysamp <- sample(seq_len(nrow(newdf13)), 500)

# using the number of grid to plot
text(newdf13[mysamp, c("Longitude","Latitude")],
     labels = newdf13[mysamp, "grids_gp"], cex = 0.8)



# Now I would like to arrange the mean of yeild according to the no of cell 
# or yeild estimates for each cell therefore returning to a function for 
# the calculation.

meanofeach_cell2013 <- setNames(Each.cell.estimates(df = newdf13, testFunc = mean),
              c("grids_gp", "mean13"))


# Now in order to check, if the data qulifies the condition that is the harvest 
# interval is less than a week, I have written a function Above and have returned
# below:

checknumberof_days(mydata = df_2013)


# Now, For the process of normalization, I have used the first option that is rank 
# to normalize the data

requiredata13 <- meanofeach_cell2013
requiredata13$Rank13 <- rank(requiredata13$mean)

```
# Calculating for the year 2015 

Repeating the same process as done for the year 2013 below


```{r}

# Returning the values on the function creepartitionof_6x20
 newdf15 <-createPartitionsOf_6X20(df=df_2015)
 
#set.seed(54321)
plot(NA,
  xlim = c(0, 600),
  ylim = c(0, 400),
  xlab = "Latitude",
  ylab = "Longitude",
  main = paste0(
    "Plot of data points at the desired grid(6x20) for the data 2015",
    sep = " "
  )
)

# plotting the required grid
grid(
  nx = 6,
  ny = 20,
  col = "blue",
  lty = "dotted",
  lwd = par("lwd"),
  equilogs = TRUE
)


 
colnames(newdf15)[colnames(newdf15) == "grid"] <-
  "grids_gp"


# I want to plot only 500 data's position in a graph to make it easier 
# to visualize
# inserting the 500 data's position
mysamp <- sample(seq_len(nrow(newdf15)), 500)


# using the number of grid to plot
text(newdf15[mysamp, c("Longitude","Latitude")],
     labels = newdf15[mysamp, "grids_gp"], cex = 0.8)


# Now I would like to arrange the mean of yeild according to the no of cell
# or yeild estimates for each cell therefore returning to a function for the 
# calculation.

meanofeach_cell2015 <- setNames(Each.cell.estimates(df = newdf15, testFunc = mean),
              c("grids_gp", "mean15"))


# Now in order to check, if the data qulifies the condition that is the harvest 
# interval is less than a week,I have written a function Above and have returned
# below:

checknumberof_days(mydata = df_2015)


# Now, For the process of normalization, I have used the first option that is rank 
# to normalize the data

requiredata15 <- meanofeach_cell2015
requiredata15$Rank15 <- rank(requiredata15$mean)

```
# Calculating for the year 2016 

Repeating the same process as done for the year 2013 below


```{r}

# Returning the values on the function creepartitionof_6x20
 newdf16 <-createPartitionsOf_6X20(df=df_2016)

#set.seed(54321)
plot(NA,
  xlim = c(0, 600),
  ylim = c(0, 400),
  xlab = "Latitude",
  ylab = "Longitude",
  main = paste0(
    "Plot of data points at the desired grid(6x20) for the data 2016",
    sep = " "
  )
)

# plotting the required grid
grid(
  nx = 6,
  ny = 20,
  col = "blue",
  lty = "dotted",
  lwd = par("lwd"),
  equilogs = TRUE
)


 
colnames(newdf16)[colnames(newdf16) == "grid"] <-
  "grids_gp"


# I want to plot only 500 data's position in a graph to make it easier 
# to visualize
# inserting the 500 data's position
mysamp <- sample(seq_len(nrow(newdf16)), 500)


# using the number of grid to plot
text(newdf16[mysamp, c("Longitude","Latitude")],
     labels = newdf16[mysamp, "grids_gp"], cex = 0.8)


# Now I would like to arrange the mean of yeild according to the no of cell or 
# yeild estimates for each cell therefore returning to a function for the calculation.

meanofeach_cell2016 <- setNames(Each.cell.estimates(df = newdf16, testFunc = mean),
              c("grids_gp", "mean16"))


# Now in order to check, if the data qulifies the condition that is the harvest interval
# is less than a week, I have written a function Above and have returned below:

checknumberof_days(mydata = df_2016)


# Now, For the process of normalization, I have used the first option that is rank to
# normalize the data

requiredata16 <- meanofeach_cell2016
requiredata16$Rank16 <- rank(requiredata16$mean)

```

# Calculating for the year 2017: 

Repeating the same process as done for the year 2013 below


```{r}

# Returning the values on the function creepartitionof_6x20
 newdf17 <-createPartitionsOf_6X20(df=df_2017)

#set.seed(54321)
plot(NA,
  xlim = c(0, 600),
  ylim = c(0, 400),
  xlab = "Latitude",
  ylab = "Longitude",
  main = paste0(
    "Plot of data points at the desired grid(6x20) for the data 2017",
    sep = " "
  )
)

# plotting the required grid
grid(
  nx = 6,
  ny = 20,
  col = "blue",
  lty = "dotted",
  lwd = par("lwd"),
  equilogs = TRUE
)


colnames(newdf17)[colnames(newdf17) == "grid"] <-
  "grids_gp"


# I want to plot only 500 data's position in a graph to make it easier 
# to visualize
# inserting the 500 data's position
mysamp <- sample(seq_len(nrow(newdf17)), 500)


# using the number of grid to plot
text(newdf17[mysamp, c("Longitude","Latitude")],
     labels = newdf17[mysamp, "grids_gp"], cex = 0.8)

# Now I would like to arrange the mean of yeild according to the no of
# cell or yeild estimates for each cell therefore returning to a function
# for the calculation.

meanofeach_cell2017 <- setNames(Each.cell.estimates(df = newdf17, testFunc = mean),
              c("grids_gp", "mean17"))


# Now in order to check, if the data qulifies the condition that is the harvest 
# interval is less than a week, I have written a function Above and have returned
# below:

checknumberof_days(mydata = df_2017)


# Now, For the process of normalization, I have used the first option that is rank to
# normalize the data

requiredata17 <- meanofeach_cell2017
requiredata17$Rank17 <- rank(requiredata17$mean)


```

# Calculating for the year 2018: 

Repeating the same process as done for the year 2013 below


```{r}

# Returning the values on the function creepartitionof_6x20
 newdf18 <-createPartitionsOf_6X20(df=df_2018)

#set.seed(54321)
plot(NA,
  xlim = c(0, 600),
  ylim = c(0, 400),
  xlab = "Latitude",
  ylab = "Longitude",
  main = paste0(
    "Plot of data points at the desired grid(6x20) for the data 2018",
    sep = " "
  )
)

# plotting the required grid
grid(
  nx = 6,
  ny = 20,
  col = "blue",
  lty = "dotted",
  lwd = par("lwd"),
  equilogs = TRUE
)


colnames(newdf18)[colnames(newdf18) == "grid"] <-
  "grids_gp"


# I want to plot only 500 data's position in a graph to make it easier 
# to visualize
# inserting the 500 data's position
mysamp <- sample(seq_len(nrow(newdf18)), 500)


# using the number of grid to plot
text(newdf18[mysamp, c("Longitude","Latitude")],
     labels = newdf18[mysamp, "grids_gp"], cex = 0.8)


# Now I would like to arrange the mean of yeild according to the no of cell or 
# yeild estimates for each cell therefore returning to a function for the 
# calculation.

meanofeach_cell2018 <- setNames(Each.cell.estimates(df = newdf18, testFunc = mean),
              c("grids_gp", "mean18"))


# Now in order to check, if the data qulifies the condition that is the harvest interval
# is less than a week, I have written a function Above and have returned below:

checknumberof_days(mydata = df_2018)


# Now, For the process of normalization, I have used the first option that is rank to 
# normalize the data

requiredata18 <- meanofeach_cell2018
requiredata18$Rank18 <- rank(requiredata18$mean)

```
Since our data qualifies the first condition and the data is normalized with rank, we are now
Merging the data with grid number for all the years data in and as `finaldata`

```{r}
finaldata <-
  Reduce(function(x,y) merge(x,y,by="grids_gp",all=TRUE),
         list(requiredata13,requiredata15,requiredata16,requiredata17,requiredata18))

```

Now, calculating normalized mean and the standard deviation
I would like to subset the means of data as a new table and calculate normalize mean and sd 
for my conviniance and merge them later.
```{r}
# names(finaldata)
# finaldatav1 <- finaldata[,c(2,4,6,8,10)]
finaldatav2 <- finaldata[,c(1,3,5,7,9)]

norm_meanv2 <- apply(finaldatav2,1, mean)

norm_sd2 <- apply(finaldatav2, 1, sd)
# max(norm_sd)
# max(norm_meanv2)


finaldata$normalise_Rmean <- norm_meanv2
finaldata$normalise_Rsd <- norm_sd2

```

Now classifying the data by quartiles for mean:
here 1st quartile is less than or equal to 25% and is mentioned
as position 1 and classified as `Low-yeild`.
3rd quartile  is greater or equal to 75% and is mentioned as position 4 and classified as
`High-yeild` 
everything between 1st quartile to 2nd quartile and 2nd quartile to 3rd quartile is 
positioned as 2 and 3 and classified as `Moderate` 


FOr Standard deviation 
Now classifying the data by quartiles for standard Deviation:
here 1st quartile is less than or equal to 25% and is mentioned
as position 1 and classified as `Stable-yeilding`.
3rd quartile  is greater or equal to 75% and is mentioned as position 4 and classified as
`Unstable-yeilding` 
everything between 1st quartile to 2nd quartile and 2nd quartile to 3rd quartile is 
positioned as 2 and 3 and classified as `Average Yeild` 

```{r}

finaldata$quartilesPos <- ntile(finaldata$normalise_Rmean, 4)
# >= 25 (low); =< 75 (high); else moderate

# Filling the Column with Moderate Yeild
finaldata$classification_by_mean <- "Moderate-yield"
# finaldata$classification_by_mean


# Applying the Conditions
finaldata$classification_by_mean[finaldata$quartilesPos <= 1] <- "Low-yield"
finaldata$classification_by_mean[finaldata$quartilesPos >= 4] <- "High-yield"


# plotting to visualize the data

finaldata %>% 
  ggplot(aes(x="",y=normalise_Rmean, label = normalise_Rmean))+
  geom_boxplot(width=.5)+ ggtitle("Box-plot for normalized mean")+
  geom_text(check_overlap = TRUE,position=position_jitter(width=0.15),
            aes(color = factor(classification_by_mean)))+
  theme(legend.position="none") 



finaldata$quartilesPos_sd <- ntile(finaldata$normalise_Rsd, 4)
# >= 25 (stable yeilding); =< 75 (unstable yeilding); else Average yeild

# First filling the column with average yeild
finaldata$classification_by_sd <- "Average yeild"
# finaldata$classification_by_sd


# Applying the Condition:
finaldata$classification_by_sd[finaldata$quartilesPos_sd <= 1] <- "stable yeilding"
finaldata$classification_by_sd[finaldata$quartilesPos_sd >= 4] <- "unstable yeilding"


# Plotting to visualize
finaldata %>% 
  ggplot(aes(x="",y=normalise_Rsd, label = normalise_Rsd))+
  geom_boxplot(width=.5)+ ggtitle("Box-plot for normalized sd")+
  geom_text(check_overlap = TRUE,position=position_jitter(width=0.15), 
            aes(color = factor(classification_by_sd)))+
  theme(legend.position="none") 

```


Now plotting graphs according to the individual rank for the year

```{r}

# first we set the position of cell to plot
finaldata$roVal <- rep(rep(1:20,each=6))
finaldata$colVal <- as.factor(rep(seq(1,6,1),20)) 

par(mfrow=c(2,2))
ggplot(finaldata, aes(y = roVal, x = colVal, fill = Rank13)) + 
  geom_tile(color = "White")+ ggtitle("Yeild rank for 2013")
ggplot(finaldata, aes(y = roVal, x = colVal, fill = Rank15)) +
  geom_tile(color = "White")+ ggtitle("Yeild rank for 2015")
ggplot(finaldata, aes(y = roVal, x = colVal, fill = Rank16)) +
  geom_tile(color = "White")+ ggtitle("Yeild rank for 2016") 
ggplot(finaldata, aes(y = roVal, x = colVal, fill = Rank17)) +
  geom_tile(color = "White")+ ggtitle("Yeild rank for 2017")
ggplot(finaldata, aes(y = roVal, x = colVal, fill = Rank18)) +
  geom_tile(color = "White")+ ggtitle("Yeild rank for 2018") 

```
# Conclusion for the individual graphs

This is the graphs for the rank of the aggregate yield mean for each year, 
darker the color, less is the rank, which means less is the yield in those grids.

For 2013 data most of the highest yield is at the middle columns and less yield on
either side of the column. Column 1 rw8 and 9 has distinct high yield.

For 2015 data the least yield is at the first column except column1 row 9 which is moderate
and the rest of the columns of the field is either moderate yield or high yield and the column 4
shows the highest yield.

For 2016 data the column 4 and 6 has the highest yield and rest of the column has the moderate or
low yield but column 9 has the high yield as in others year data.

For 2017 data the first and the second column has a low yield whereas remaining other column has
the mix yield

For 2018 data the upper half of the first column and the upper half of the last column has the low yield
and moderate yield in between these columns.

variation in the yield for e different year maybe because of the amount of rainfall or the climate of that year,
types of crops planted, quality of the seed, and many other factors.



 Now Plotting the graphs for the mean of normalized data
```{r}
par(mfrow=c(2,2))
ggplot(finaldata, aes(y = roVal, x = colVal, fill = normalise_Rmean)) +
  geom_tile(color = "White")+ ggtitle("Normalized mean")

ggplot(finaldata, aes(y = roVal, x = colVal, fill = classification_by_mean)) +
  geom_tile(color = "White")+ ggtitle("Classification by the mean")

```

# Conclusion for the above graph 1 Normalized mean

Here, lighter the color of the grid more is the amount of the yield in that grid, and darker the color
of the grid, less is the yield for that grid.
Therefore, from the graphs above we can conclude that except column 1 row 9 of column 1 has a low yield.
And the column 4 row 19 and 20 has the highest along with the row 9 and 10 of the same column.
Likewise, in the 6th column, we can say that 1, 2,3 rows of 6th column and 13, 14 and 20th column of the
the last column has a better yield in column 6.
Hence, the outcome is better in between the 1 and 6 column.we can use out time and more in that area.

# Conclusion for the graphs 2 Classification by mean

Form graph 2 it is quite clear, Color `Red` denotes the field with the highest yield, Color `green` 
denotes the low yield, likewise Color `blue` denotes the moderate yield.
Therefore we can say plan and harvest accordingly in those fields. 

Since this is the mean of all the data, we can say that the field with the highest yield has the most outcome in yield.
so we can contribute our more time and money in those fields for better yield.

The field with low-yield might have various factors contributing to  the low-yield, for example, those fields 
maybe less irrigated, or the field itself is not so fertile.  

```{r}
par(mfrow=c(2,2))
ggplot(finaldata, aes(y = roVal, x = colVal, fill = normalise_Rsd))+
  geom_tile(color = "White")+ ggtitle("Normalized standard deviation")

ggplot(finaldata, aes(y = roVal, x = colVal, fill = classification_by_sd)) +
  geom_tile(color = "White")+ ggtitle("Classification by the mean")

```


# Concusion for the Normalized by sd

Here Lighter the color of the grid more unstable is the field data which means that there might 
be various factors affecting the crops and its yield. The Darker color in the filed denotes that its
stable and nothing has effected its yield. 

# Conclusion for the Classification by SD

Here, Color Red denotes the average yield, green denotes the stable yielding and blue
denotes the unstable yielding.That means the color red denotes that the yield has an 
average yield. Color green denotesthat the yield does not affectby the external 
situation or the types of crops. This field produces an equal amount in all
kinds of crops in different years.Likewise blue is unstable which means that the yield
is more in some crops and less in others. 




