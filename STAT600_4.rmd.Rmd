---
title: "Homework 4 Arrays and Lists"
author: 'Yamuna Dhungana'
date: 'June 24 2020'
output:
  pdf_document: default
  html_document: default
---

```{r,echo=FALSE}
options(digits=12)
```

# Instructions

There are six exercises below. You are required to provide five solutions, with the same options for choosing languages as with the last exercise. Four exercises refer to formula from the previous homework, you may reuse code as you wish. You can provide solutions in two languages for one exercise only (for example, Ex. 1,2,3,5 in R and Ex. 1 in SAS is acceptable, Ex. 1,2,3 in SAS and Ex. 1,2 in R is not).

## Reuse

For many of these exercises, you may be able to reuse functions written in prior homework. Include those functions here. You may find that you will need to modify your functions to work correctly for these exercises.

I'm also including data vectors that can be used in some exercises.

```{r}
CaloriesPerServingMean <- c(268.1, 271.1, 280.9, 294.7, 285.6, 288.6, 384.4)
CaloriesPerServingSD <- c(124.8, 124.2, 116.2, 117.7, 118.3, 122.0, 168.3)
Year <- c(1936, 1946, 1951, 1963, 1975, 1997, 2006)
```

# Exercise 1. 

### Part a.

We will produce a graph similar to the graph in Homework 1, but we will plot effect size by year instead of mean by year, and there will be no error bars.

Define $m_1$ to be the 7 means for Calories per Serving from Wansink Table 1. Define $m_2$ to be the single mean for Calories per Serving, 1936. Similarly, define $s_1$ to be the 7 standard deviations from Wansink Table 1 and define $s_2$ to be the single standard deviation for Calories per Serving, 1936.

Calculate Cohen's $d$ for each $m_1$ vs $m_2$ using vector operations; you may also use your previously defined function. The result will be a vector of effect sizes relative to 1936 (the first will be 0). Plot this vector against a vector composed of the publication years $1936, 1946, \dots, 2006$

Add to this plot three horizontal lines, one at $d=0.2$, one at $d=0.5$ and one at $d=0.8$. You should use different colors or different styles for each line. Should any of the effect sizes be considered *large*?

```{r}
m_1 <- c(268.1, 271.1, 280.9, 294.7, 285.6, 288.6, 384.4)
m_2 <- c(268.1)
s_1 <- c(124.8, 124.2, 116.2, 117.7, 118.3, 122.0, 168.3)
s_2 <- c(124.8)
Year <- c(1936, 1946, 1951, 1963, 1975, 1997, 2006)
cohens_d = (abs(m_1-m_2)/(sqrt((s_1^2+s_2^2)/2)))
effect_size <- round(cohens_d, digit = 2)
effect_size
a <- data.frame(Year,effect_size)
a
#plotting graph
library(ggplot2)
ggplot(a, aes(x=Year,y= effect_size))+ 
geom_line(colour= "black",size = 1.01)+
ggtitle("Effect size vs year")+
geom_hline(yintercept= c(0.2,0.5,0.8), color=c("blue","green","red"))

```
Answer: To consider effect size as a large, effect size should be 0.8 whereas, in my graph none if the value is 0.8. Therefore it cannot be considered as large.


# Exercise 2

Create a table to show the required replicates for a range of combinations of $\%Diff$ and $CV$. Do this in steps as follows:

### Part a.
Define two matrices, one for `CV` and one for `Diff`. Each matrix will be 5 rows by 6 columns. Let the rows in `CV` be the sequence $8, 12, ..., 28$ and let the columns of `Diff` be the squence $5,10, ... , 25$. The matrices should look like:

$$
\begin{aligned} 
 CV & = \left\{
 \begin{array}{cccccc}
     8 & 12 & 16 & 20 & 24 & 28  \\
     8 & 12 & 16 & 20 & 24 & 28  \\
     \vdots & \vdots & \vdots & \vdots & \vdots  & \vdots \\
     8 & 12 & 16 & 20 & 24 & 28  \\
   \end{array}
   \right\} \\
   & \\
 Diff & = \left\{
 \begin{array}{cccccc}
     5 & 5 & 5 & 5 & 5 & 5 \\
     10 & 10 & 10 & 10 & 10 & 10\\
     \vdots & \vdots & \vdots & \vdots & \vdots & \vdots\\
     25 & 25 & 25 & 25 & 25 & 25 \\
   \end{array}
   \right\}
\end{aligned} 
$$

Define and print your matrices in the code below.

```{r}
cv <- matrix(seq(8,28,by=4),nrow=5, ncol=6, byrow= TRUE)
diff <- matrix(seq(5,25,by=5),nrow=5, ncol=6, byrow= FALSE)
print(cv)
print(diff)
```

### Part b.

Calculate require replicates for each combination of `CV` and `Diff`. Use $\alpha=0.05$ and $\beta=0.2$. You should be able to reuse code from previous exercises, and you should not use iteration.

Print the result below. The result should be a $5 \times 6$ matrix.

```{r}
combined <- function(alpha,beta) {
z_alpha = qnorm(alpha/2, mean=0, sd= 1)
z_beta = qnorm(beta, mean=0, sd= 1)
cv = matrix(seq(8,28,by=4),nrow=5, ncol=6, byrow= TRUE)
per_diff = matrix(seq(5,25,by=5),nrow=5, ncol=6, byrow= FALSE)
n = ceiling(2*(((cv/per_diff)^2)*(z_alpha+z_beta)^2))
return(n)
}
s <- combined(alpha=0.05, beta=0.2)
s
```

To check your work, repeat the calculations using the rule of thumb from the previous exercises. What is largest deviation of the rule of thumb from the exact calculation? I find that for about half the combinations of `CV` and `Diff`, the two methods are identical; for most the difference is 1 or less.

For this, first we can simplify the equations as follows:
first for CV,

$CV = \frac{sd_{pooled}}{(m_1 + m_2)/2}$
$(m_1 + m_2)/2) = \frac{sd_{pooled}}{CV/2}$
$(m_1 + m_2)/2) = {2} \times\frac{sd_{pooled}}{CV}$

then, for $\%diff$: 

$\%Diff = \frac{m_1 - m_2}{(m_1 + m_2)/2}$
$\%Diff\times\frac{(m_1 + m_2)}{2} = m_1-m_2$
$m_1-m_2 = \frac{\%Diff}{2}\times(m_1 + m_2)$

Now, if we replace $m_1 + m_2$, we get:
$m_1-m_2 = \frac{\%Diff}{2}\times ({2} \times\frac{sd_{pooled}}{CV})$

Or, $m_1-m_2 = \frac{{\%Diff } \ \times\ {sd_{pooled}}}{CV}$

This will give us delta ($\triangle$): 
$\triangle = \frac{m_1-m_2}{sd_{pooled}} = \frac{1}{sd_{pooled}} \times \frac{{\%Diff } \ \times\ {sd_{pooled}}}{CV} = \frac{\%Diff}{CV}$

Now we can use, rule of thumb as:
$n = \frac{16}{\triangle^2}$


```{r}
#rule of thumb

cv = matrix(seq(8,28,by=4),nrow=5, ncol=6, byrow= TRUE)
per_diff = matrix(seq(5,25,by=5),nrow=5, ncol=6, byrow= FALSE)
n <- ceiling(16/(per_diff/cv)^2)
n
comparision = n-s
comparision
```

```{r}
dev= max(n-s)
print(paste("The largest deviation is:",dev , sep =" "))
```
# Exercise 3 Not to be graded

In this exercise, we will test your `norm.pdf` function with a range of inputs.

**Do not print the vectors you create for this exercise in the final typeset submission** We will check the results by examining the plots, and printing the vectors themselves will unnecessarily clutter your report. If you get stuck, use the built normal functions to create your plots.

### Part a.

Generate a squence of values from $-3,...,3$ incremented by $0.1$; let this be `x_1`. 
Calculate the likelihood of each value of `x_1` using the `norm.pdf` function from Homework 3, letting `mu=0` and `sd=1`. Plot the likelihood curve ($L$ is the dependent variable, $x$ is independent) as a line graph.

```{r}
#norm.pdf <- function(x, sigma=1, mu,sd) { 
 # like1 <- (1/(sigma*(sqrt(2*pi))))* (exp(-((x-mu)^2)/2*(sigma^2))) 
  #return(like1)
#}
#x = seq(-3,3,by=0.1)
#l <- norm.pdf(x,mu=0, sd=1)
#plot(x,l)

```

### Part b.

Let $m_{1936}$ be the mean Calories per Serving from 1936, and let $m_{2006}$ be the mean Calories per Serving, 2006. Let $s_{1936}$ and $s_{2006}$ be the corresponding standard deviations.

Create two sequences and name these `x_2` and `x_3`. Define `x_2` to be a range of values $[m_{1936} - 3\times s_{1936}, \dots, m_{1936} + 3\times s_{1936}]$ and define `x_3` to be $[m_{2006} - 3\times s_{2006}, \dots, m_{2006} + 3\times s_{2006}]$. `x_2` and `x_3` should be the same length as `x_1`.

Calculate the corresponding likelihood for these sequences, using $\{\mu=m_{1936},\sigma=s_{1936}\}$ with `x_2` and use $\{\mu=m_{2006},\sigma=s_{2006}\}$ with `x_3`.

As with part a, plot the likelihood curve for both sequences, but include both in the same graph. Use two different colors or line types for each curve. You may need to use `min` and `max` to find `xlim` values or `ylim` to fit both curves on the same plot. The first curve in this graph should appear identical to the curve in part a; the second curve will be similar but will differ in location and spread.


```{r}
# function definition 

#a <- seq(-3,3, by = 0.1)
#liklihood <- function(x, sd= sigma, mean= mu) {
#like1 <- (1/(sigma*(sqrt(2*pi))))* (exp(-((x-mu)^2)/2*(sigma^2))) 
#return(like1)
#}

#m_1936 = 268.1
#s_1936 = 124.8
#x_2 <- (m_1936 + s_1936*(a))
#plot_36 <- liklihood(x=x_2, mean= m_1936, sd= s_1936)
#plot_36

#m_2006 =384.4
#s_2006 = 168.3
#x_3 <- (m_2006 + s_2006*(a))
#plot_06 <- liklihood(x=x_3, sd = s_2006, mean = m_2006)
#plot_06


#plot(x_2,plot_36)
#plot(x_3,plot_06)
```


If you choose to solve this with SAS, I've included code in the SAS template to create the graphs, since combining plots in IML is not as easy as in R.

If you wish, you may reproduce the curves using `dnorm` to compare with your function.

# Exercise 4

Suppose we wish to determine the linear relationship between per Calories per Serving and Year. We can determine this by solving a system of linear equations, of the form

$$
\begin{aligned}
268.1 & = \beta_1 + \beta_2 \times 1936 \\
271.1 & = \beta_1 + \beta_2 \times 1946  \\
\vdots & = \vdots \\
384.4 & = \beta_1 + \beta_2 \times 2006 \\
\end{aligned}
$$

We write this in matrix notation as

$$
\left(\begin{array}{c}
268.1 \\
271.1 \\
\vdots \\
384.4 
 \end{array}\right) 
 =
 \left(\begin{array}{rr}
 1 & 1936 \\
 1 & 1946  \\
\vdots & \vdots \\
 1 & 2006
 \end{array}\right) 
 \left(\begin{array}{c}
 \beta_1 \\
 \beta_2
 \end{array}\right)^t
$$

We can also write this as 

$$
\mathbf{y} = \mathbf{X} \mathbf{\beta}
$$ 

and find a solution by computing $\mathbf{\widehat{\beta}} = \mathbf{X}^{- 1}\mathbf{y}$. 

However, an exact solution for the inverse, $\mathbf{X}^{- 1}$ require square matrices, so commonly we use the *normal* equations, 

$$ \mathbf{X}^{t}  \mathbf{y} = \mathbf{X}^{t} \mathbf{X}  \mathbf{\beta} $$
(where $\mathbf{X}^{t}$ is the transpose of $\mathbf{X}$). We then find 

$$
\widehat{\mathbf{\beta}} = \left(\mathbf{X}^{t} \mathbf{X} \right)^{-1} \mathbf{X}^{t} \mathbf{y}
$$


### Answer

Define appropriate `X` and `y` matrices (`y` can be a vector in R) in the chunk below.

Multiply the transpose of `X` by `X`, then use `solve` (R) or `inv` (IML) to find the inverse $\left(\mathbf{X}^{t} \mathbf{X} \right)^{-1}$. Multiply this by the product of transpose `X` and `y` to find `hat.beta`.

Print your `hat.beta`.

```{r}
y <- matrix(c(268.1, 271.1, 280.9, 294.7, 285.6, 288.6, 384.4), byrow = FALSE)
y
#creating a matrix for bias term
bias=rep(1:1, length.out=length(y))
bias

cx <- c(1936, 1946, 1951, 1963, 1975, 1997, 2006)
X=matrix(c(bias,cx), ncol = 2)
X
#multplication of transpose of x and x
tX=t(X)
tX

Xm=tX%*%X
Xm

A=solve(Xm)

hat.beta=A%*%(tX%*%y)
hat.beta


```


To check your work, calculate the values predicted by your statistical model. Compute `hat.y` by multiplying `X` and `hat.beta`,
$$\widehat{y} = \mathbf{X}  \widehat{\beta}$$
Plot `y` vs the independent variable (the second column of `X`) as points, and `hat.y` vs  independent variable  as a line, preferably a different colors. The `hat.y` values should fall a straight line that interpolates `y` values.

```{r}
# compute hat.y 
hat.y <- X %*% hat.beta
# plot
plot(X[,2], y, type = 'l', col = "black")
lines(X[,2], hat.y, col = "blue")
```

You can also compare your result to the R function (set `eval=TRUE`).

```{r,eval=TRUE}
summary(lm(y~X))
```


#### Alternative methods
You can also compute $\widehat{\beta}$ by passing both $\mathbf{X}^{t} \mathbf{X} ^{-1}$ and
$\mathbf{X}^{t} \mathbf{y}$ as arguments to `solve`.

Alternatively, you can install the `MASS ` library and use `ginv` to compute a generalized inverse $\mathbf{X}^{- 1}$. Use this to compute $\mathbf{\widehat{\beta}} = \mathbf{X}^-\mathbf{y}$ in the chunk below:

```{r,eval=FALSE}
library(MASS)
print(hat.beta <- ginv(X) %*% y)
```


# Exercise 5

Given a vector of mean estimates $x = x_1, x_2, \dots, x_k$, a vector of standard deviations $s = s_1, s_2, \dots, s_k$ and a vector of sample sizes $n = n_1, n_2, \dots, n_k$, we can calculate a one-way analysis of variance by

$$
MSB = \frac{n_1(x_1-\bar{x})^2 + n_2(x_2-\bar{x})^2 + \dots + n_k(x_k-\bar{x})^2} {k-1} = \frac{\sum_i n_i(x_i-\bar{x})^2}{k-1}
$$
and

$$
MSW = \frac{(n_1-1)s_1^2 + (n_2-1)s_2^2 + \dots (n_k-1)s_k^2 }{N-k} = \frac{\sum_i (n_i-1)s_i^2}{N-k}
$$

where $\bar{x}$ is the weighted mean of $x_i = \frac{\sum_i n_i * x_i}{N}$ and $N = \sum_i n_i$. The test statistic is $F = \frac{MSB}{MSW}$ which is distributed as $F_{\alpha,k-1,N-k}$

### Part a

Calculate MSW and MSB for Calories per Serving from Wansink Table 1. You can use the variables `CaloriesPerServingMean` and `CaloriesPerServingSD` defined below. Let $n_1 = n_2 ... = n_k = 18$

Use array functions and arithmetic for your calculations, you should not need iteration (for loops). Do not hard code values for $N$ and $k$, calculate these from the `CaloriesPerServingMean` or `CaloriesPerServingSD`. 
 
Print both MSB and MSW.

```{r}

CaloriesPerServingMean <- c(268.1, 271.1, 280.9, 294.7, 285.6, 288.6, 384.4)
CaloriesPerServingSD <- c(124.8, 124.2, 116.2, 117.7, 118.3, 122.0, 168.3)

# for mean 

k <- length(CaloriesPerServingMean)
n_i <- rep(18, k)
n_i
N = sum(n_i)
N
x_bar = sum(CaloriesPerServingMean*n_i)/N
x_bar
x_i <- CaloriesPerServingMean

MSB = (sum(n_i*(x_i - x_bar)^2))/(k-1)
MSB
s_i <- CaloriesPerServingSD

MSW <- (sum((n_i-1)*s_i^2)/(N-k))
MSW

```

### Part b
Calculate an F-ratio and a $p$ for this $F$, using the $F$ distribution with $k-1$ and $N-k$ degrees of freedom. Use $\alpha=0.05$. Compare these values to the corresponding values reported in Wansink Table 1.

```{r}
# Calculating F.ratio
F.ratio <- MSB/MSW
df1 <- k-1
df2 <- N-k
p.value <- pf(F.ratio, df1, df2, lower.tail = FALSE)
p.value

```


You can also check results by entering appropriate values in an online calculator like http://statpages.info/anova1sm.html .

# Exercise 6

In this, we compare the normal and Poisson distributions, using the functions you've written previously. This is also a way to test your normal and Poisson functions over a range of arguments. 

**Do not print the vectors you create for this exercise in the final typeset submission** We will check the results by examining the plots, and printing the vectors themselves will unnecessarily clutter your report. If you get stuck, use the built functions to create your plots. However, the final submission must call your functions.

### Part a

Create a sequence of $x_a$ from $( -5 ... 5 )$, incremented by 0.1. Calculate the normal likelihood for each $x$, assuming $\mu=0$ and $\sigma=1$. Also calculate Poisson probability of each $x$ given a `lambda=1`.

Plot both sets of probablities against `x_a` as lines, using a different color for each curve. Make sure that both curves fit in the plot; you may need to determine minimum and maximum values and set these as graphic parameters (see `ylim`).

Warning: if you do this in SAS, you may have to adjust the lower bound of $x$.

```{r}
# Suppressing warnings that may be generated by Poisson function for negative values
# options(warn=-1)

x_a <- seq(-5, 5, 0.1)
x_a
norm.pdf <- function(x,mu=0,sigma=1){
  l<-1/(sigma*sqrt(pi*2))*exp(-((x-mu)^2)/(2*sigma^2))
  return(l)
}
normal.liklihood.x_a <- norm.pdf(x_a)


# The function to calculate probability mass function for poisson 
# data with a mean and variance lambda = 1. 
pois.pmf <- function(x, lambda){
  poisson.d <- exp(-lambda)*(1/(factorial(round(x,0))))*exp(round(x,0)*(log(lambda)))
  return(poisson.d)
}
lambda <- 1
poisson.probability.x_a <- pois.pmf(x=x_a, lambda = lambda)

plot(x_a,normal.liklihood.x_a,type="l",col="black")
lines(x_a,poisson.probability.x_a,col="red")

```

Does this graph tell you if your Normal PDF function behaves properly?  Does your Poisson handle negative or non-integer values as expected? You might need to call a rounding function on the parameters inside your function.

No, according to the plot, normal pdf does behave properly but not poisson.
### Part b

Create a sequence of $x_b = \left \lfloor{\mu - 5 \times \sigma } \right \rfloor , \dots, \left \lceil{\mu+ 5 \times \sigma }  \right \rceil$ using mean and standard deviation for Servings per Recipe from 1936.

Calculate the normal and Poission probability for each $x_b$ as in part a, again using mean and standard deviation from servings per recipe, 1936. The length of this vector should be the same length as the $x_a$ vector as in part a ($\pm 1$), so you will need to calculate an interval based on the range `x_b` and the number of elements in `x_a`

Show the the length of both $x$ vectors are similar by calling `length` for each.

Repeat the plot from part a with this sequence.

If you choose to solve this with SAS, I've included code in the SAS template to create the graphs, since combining plots in IML is not as easy as in R.


```{r}
# Using mean and standard deviation for servings per recipe from 1936:
mu = 12.9; sigma = 13.3

# Now we find the upper and lower bounds as:
x.lower <- floor(mu-5*sigma)
x.upper <- ceiling(mu+5*sigma)

# Now taking the length of x_a as a reference, we create the equeally spaced
# sequence from lower to upper bound as followed:
spacer <- (x.upper - x.lower)/(length(x_a) - 1)

x_b <- seq(x.lower, x.upper, spacer)
# To show both x_a and x_b 's lenghts are equal:
length(x_a)
length(x_b)

norm.pdf <- function(x, mu = 12.9, sigma = 13.3){
  l<-1/(sigma*sqrt(pi*2))*exp(-((x-mu)^2)/(2*sigma^2))
  return(l)
}
normal.liklihood.x_b <- norm.pdf(x_b)


# The function to calculate probability mass function for poisson 
# data with a mean and variance lambda = 12. 
pois.pmf <- function(x, lambda){
  poisson.d <- exp(-lambda)*(1/(factorial(round(x,0))))*exp(round(x,0)*(log(lambda)))
  return(poisson.d)
}

#using sigma = 13.3 to compare the difference with the first plot
poisson.probability.x_b <- pois.pmf(x=x_b, lambda = 12)

# plot
plot(x_b,normal.liklihood.x_b,type="l",col="black")
lines(x_b,poisson.probability.x_b,col="red")
```

To check you work, duplicate the plots by calling built in normal and Poisson functions. Does the built in Poisson function handle negative $x$ differently than your function?

Yes, possion function handles negative and non- integer values differently.

```{r}
# Using base functions for part a  
base.normal.liklihood.x_a <- dnorm(x_a,0, 1)
base.poiss.x_a <- dpois(x=x_a, lambda = lambda)

plot(x_a,base.normal.liklihood.x_a,type="l",col="black")
lines(x_a,base.poiss.x_a,col="red")

# Using base functions for part b
base.normal.liklihood.x_b <- dnorm(x_b,0, 1)
base.poiss.x_b <- dpois(x=x_b, lambda = 12)

plot(x_b,base.normal.liklihood.x_b,type="l",col="black")
lines(x_b,base.poiss.x_b,col="red")
```
